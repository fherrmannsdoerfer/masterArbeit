\chapter{Data processing}
\section{the camera}
\subsection{dark current}

\section{the data}
The datasets for STORM microscopy that we recieve from our collaborators from
Bioquant are big datasets of several gigabyte in the Andor .sif format. Each
file conains a stack of pictures, normaly between 1000 and 10000, taken
consecutively.
In each picture there are beads and signals. Both result from very small 
fluorescent molecules attached to the structures that are investigated. The
light of this pointlike objects is dissorted to a gaussian shaped signal due to
the large magnification.
Beads are molecules that emit light at any time contrary to the other signal
which blinks that means it is visible in just one frame at an explicit location.
The beads are used as landmarks for later alignment of two or more different
color channels. The other spots are the structure that the biologist are
interested in. Each of the gaussian shaped signals should be recognized and the
center will be determined with subpixel accuracy and is stored in the end in a
list to be further processed by the colorcomposer application.

\section{Parameters and options}
\subsection{Necessary}

\section{Import and processing}
The STORM data has usually a size of around 3 gigabyte. There are even larger datasets possible, so that it is important to work on smaller parts of the data, instead putting the whole dataset into memory. This is done using chunks of user defined size. The data is processed chunkwise, there is parallelisation for the frames of each chunk. This is possible because the signals in each frame are considered to be independent from each other.  

\section{Workflow}
\subsection{Chose parameters}
At the begining the user has the option to set all important parameters, if no parameter is set the default ones are used and will give a good result because all crucial parameters are either determined from the data or set to reasonable values that work for every data set.
\subsection{Estimating camera gain and offset}
First of all it is checked whether there exists a file containing settings for gain and offset from an earlier run. If this is not the case new parameters are estimated based on the first part of the data, usually 200 frames are sufficiant.
The method described by \cite{skellam} is used to estimate the
gain factor. For this methode a Skellam distribution is used. 
Each dataset is three-dimensional where time is the third
dimension. Therefore mean $\mu$ and variance $\sigma^2$ can be calculated from
the data for each pixel individually
\begin{align}
	\mu(i,j) & = \frac{\Sigma_t(I_t(i,j)-I_{t+1}(i,j))}{n}\\
	\sigma^2 & = \frac{\Sigma_t(\mu-(I_t(i,j)-I_{t+1}(i,j)))^2}{n-1}
\end{align} 
To determine the gain factor the Skellam parameter are plotted over the mean
intensities. A straight line can be fitted and its slope is exactly the gain
factor.
\subsection{Recursevly adjusting gain and offset}
After the estimation of gain factor and offset, the transformation described in \ref{trafoPoiss} is applied.
\subsection{Estimating the width of the point spread function}
\subsection{Processing the data}
\subsubsection{Background estimation}
\subsubsection{Filter data}
\subsubsection{Find maxima}
\subsubsection{Quality control for detections}





\section{Background estimation}


\section{Mask for noise supression}
\section{Calibration measurement and plausibility}


\section{Accuracy of detection}
Unfortunately the position of the flourescent molecules can't be detected
perfectly. There are three main contribution to the error in detection.\\
First, there is the problem of finding the maximum in a noisy signal. Due to
noise the pixel next to the true maximum might get some intensity and be
therefore brighter.\\
Second, the choice of the gain factor and the offset might influence the
precision.\\
Third, the position is deteted by upscaling the pixel grid and interpolation.
After that the maximums position of the upscaled grid is taken as the resulting
position. This gives an error from roughly pixelwidth divided by square root of
two.
\subsection{error from noise}
Because there is no ground truth availible for micoscropy data, data must be
generated. This was done similar as described by \cite{simulated}.
\subsection{error from parameter estimation}

\section{Comparison with older version of the storm algorithm}
\section{Bleaching signal}

\section{Check for slope using calibration}
As described by \cite{meanVar} the true slope can be determined.

\section{New graphical user Interface}